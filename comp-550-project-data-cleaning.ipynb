{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 550 Project - Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Samy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import block\n",
    "import os\n",
    "import pickle\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "nltk.download('punkt') # link to documentation on punkt tokenizers: https://www.nltk.org/_modules/nltk/tokenize/punkt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Storage - 20 Newsgroup\n",
    "### This notebook assumes that you've downloaded the [20 newsgroups dataset](https://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups) and unpacked the tarball in the same directory as this notebook. \n",
    "\n",
    "### You should therefore have a folder called \"20_newsgroup\" in the same directory as this notebook. The \"20_newsgroup\" folder should have 20 subfolders (\"comp.os.ms-windows.misc\", \"soc.religion.christian\", \"rec.sport.baseball\", etc...), each containing a long list of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Format - 20 Newsgroup\n",
    "### Fortunately, the files are all raw text. Unfortunately, their headers can vary quite a lot. Take the following examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample file #1 from alt.atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath(os.path.join(os.getcwd(), \"20_newsgroups\", \"alt.atheism\", \"51128\"))) as atheism_sample_file_1:\n",
    "    print(''.join(atheism_sample_file_1.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample file #2 from alt.atheism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath(os.path.join(os.getcwd(), \"20_newsgroups\", \"alt.atheism\", \"49960\"))) as atheism_sample_file_2:\n",
    "    print(''.join(atheism_sample_file_2.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample file #1 from alt.autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath(os.path.join(os.getcwd(), \"20_newsgroups\", \"rec.autos\", \"101553\"))) as auto_sample_file_1:\n",
    "    print(''.join(auto_sample_file_1.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample file #2 from alt.autos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.abspath(os.path.join(os.getcwd(), \"20_newsgroups\", \"rec.autos\", \"103338\"))) as auto_sample_file_2:\n",
    "    print(''.join(auto_sample_file_2.readlines()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Format (cont'd)\n",
    "### The four examples above each had a \"Subject\" line in their headers, and it might be useful to use the subsequent words in our analysis. I however believe that we should only do so if we can do it consistently (for every file in every newsgroup), so I checked that every file in the 20 newsgroups had a line starting with \"Subject:\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "root_dir = '\\\\\\\\?\\\\' + os.path.abspath(os.path.join(os.getcwd(), '20_newsgroups'))\n",
    "file_count = 0\n",
    "missing_subject_line_count = 0\n",
    "total_files_count = 0\n",
    "subdirectory_list = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "for subdir in subdirectory_list:\n",
    "    files = [ os.path.join(root_dir, subdir, f) for f in os.listdir(os.path.join(root_dir, subdir)) if '.onetoc2' not in f ]\n",
    "    total_files_count += len(files)\n",
    "    for current_file in files:\n",
    "        with open(current_file,'r') as input_file:\n",
    "            contents = input_file.readlines()\n",
    "        found_subject_line = False\n",
    "        for line in contents:\n",
    "            if \"subject:\" in line.lower():\n",
    "                found_subject_line = True\n",
    "                break\n",
    "        if not found_subject_line:\n",
    "            print(f\"{current_file} didn't have a subject line.\")\n",
    "            missing_subject_line_count += 1\n",
    "        file_count += 1\n",
    "\n",
    "print(f\"examined a total of {file_count} files out of {total_files_count}, {missing_subject_line_count} of which didn't have a subject line.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OK, so every file has a subject line that we can use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Extraction\n",
    "### Some heuristics:\n",
    "1. The subject line for every file will be considered as valid content.\n",
    "2. All lines below the \"Lines: #\" line will be considered as valid content. Some invalid lines may be included (e.g. \"NNTP-Posting-Host: punisher.caltech.edu\", or \"sandvik@newton.apple.com (Kent Sandvik) writes:\"), but we can process those lines' contents afterwords with NLTK or another english dictionary API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### super_dictionary is a dictionary with subdirectory::dict() key::value pairs. The values start off as empty dictionaries, but they are eventually populated with filename::list(valid lines) key::value pairs. \n",
    "\n",
    "### In case that's not clear, super_dictionary is supposed to end up looking like a tree like this:\n",
    "\n",
    "    super_dictionary = {\n",
    "\n",
    "        'alt.atheism' : {\n",
    "\n",
    "                            '49960' : [ list of all the valid lines in file 49960 in the 'alt.atheism' subdirectory ],\n",
    "\n",
    "                            '51060' : [ list of all the valid lines in file 51060 in the 'alt.atheism' subdirectory ],\n",
    "\n",
    "                            ...\n",
    "\n",
    "                        },\n",
    "\n",
    "        'comp.graphics' : {\n",
    "\n",
    "                              '37261': [ list of all the valid lines in file 37261 in the 'comp.graphics' subdirectory ],\n",
    "\n",
    "                              '37913': [ list of all the valid lines in file 37913 in the 'comp.graphics' subdirectory ],\n",
    "\n",
    "                              ...\n",
    "\n",
    "                          } ,\n",
    "\n",
    "        ...\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_dictionary = {\n",
    "    'alt.atheism': dict([]), \n",
    "    'comp.graphics': dict([]), \n",
    "    'comp.os.ms-windows.misc': dict([]), \n",
    "    'comp.sys.ibm.pc.hardware': dict([]), \n",
    "    'comp.sys.mac.hardware': dict([]), \n",
    "    'comp.windows.x': dict([]), \n",
    "    'misc.forsale': dict([]), \n",
    "    'rec.autos': dict([]), \n",
    "    'rec.motorcycles': dict([]), \n",
    "    'rec.sport.baseball': dict([]), \n",
    "    'rec.sport.hockey': dict([]), \n",
    "    'sci.crypt': dict([]), \n",
    "    'sci.electronics': dict([]), \n",
    "    'sci.med': dict([]), \n",
    "    'sci.space': dict([]), \n",
    "    'soc.religion.christian': dict([]), \n",
    "    'talk.politics.guns': dict([]), \n",
    "    'talk.politics.mideast': dict([]), \n",
    "    'talk.politics.misc': dict([]), \n",
    "    'talk.religion.misc': dict([])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating super_dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '\\\\\\\\?\\\\' + os.path.abspath(os.path.join(os.getcwd(), '20_newsgroups'))\n",
    "file_count = 0\n",
    "subdirectory_list = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "for subdir in subdirectory_list:\n",
    "    files = [ os.path.join(root_dir, subdir, f) for f in os.listdir(os.path.join(root_dir, subdir)) if '.onetoc2' not in f ]\n",
    "    for current_file in files:\n",
    "        lines_with_valid_content = []\n",
    "        with open(current_file,'r') as input_file:\n",
    "            contents = input_file.readlines()\n",
    "\n",
    "        for i, line in enumerate(contents):\n",
    "            if \"lines: \" in line.lower():\n",
    "                lines_with_valid_content.append(line.rstrip())\n",
    "                break\n",
    "        \n",
    "        i += 1   \n",
    "        while i < len(contents):\n",
    "            lines_with_valid_content.append(contents[i].rstrip())\n",
    "            i += 1\n",
    "        \n",
    "        subdirectory_dictionary = super_dictionary[subdir]\n",
    "        subdirectory_dictionary[os.path.basename(current_file)] = lines_with_valid_content\n",
    "        \n",
    "        file_count += 1\n",
    "\n",
    "print(f\"examined a total of {file_count} files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visually validating that the super_dictionary's end-value lists have the correct content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_atheism_dictionary = super_dictionary[\"alt.atheism\"]\n",
    "print('\\n'.join(alt_atheism_dictionary[\"49960\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling super_dictionary into 20_newsgroup_content_dictionary.pickle in the root directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20_newsgroup_content_dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(super_dictionary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# just to show that pickling works\n",
    "#with open('20_newsgroup_content_dictionary.pickle', 'rb') as handle:\n",
    "#    b = pickle.load(handle)\n",
    "#\n",
    "#print(super_dictionary == b)\n",
    "#del b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "### For every leaf node (file) in the super_dictionary, we need to \"clean\" the leaf node's list of valid lines. \n",
    "### This can be done in a number of ways: here I've used NLTK's punkt tokenizer (https://www.nltk.org/_modules/nltk/tokenize/punkt.html), as it can tokenize with non-alphanumeric characters as well as with spaces. See the toy example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_some_alphanumeric_characters(line):\n",
    "    if re.search('[a-zA-Z]', line):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def tokenize(list_of_lines, verbose=False):\n",
    "    tokenized_list = []\n",
    "    for line in list_of_lines:\n",
    "        tokens = [word for word in nltk.word_tokenize(line) if has_some_alphanumeric_characters(word)]\n",
    "        if verbose:\n",
    "            print('The line \"{}\" becomes:\\n{}\\n\\n'.format(str(line), ', '.join(tokens)))\n",
    "        for tok in tokens:\n",
    "            tokenized_list.append(tok)\n",
    "    return tokenized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example_list_of_valid_lines = [\"NNTP-Posting-Host: punisher.caltech.edu\",\n",
    "                                   \"sandvik@newton.apple.com (Kent Sandvik) writes:\",\n",
    "                                   \">>To borrow from philosophy, you don't truly understand the color red\",\n",
    "                                   \">>until you have seen it.\"] # taken from /alt.atheism/51128\n",
    "#help(re.search)\n",
    "\n",
    "tokenized_toy_example = tokenize(toy_example_list_of_valid_lines, verbose=True)\n",
    "\n",
    "print(f\"\\nThe tokens in the toy example are: {', '.join(tokenized_toy_example)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As mentioned above, there are a number of different ways to clean this sort of data. Another (possibly >= useful) method would be to tokenize by spaces and remove (entirely) tokens containing characters which are neither alphanumeric nor punctuation marks (specifically apostrophes and hyphens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(Counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_and_frequencies = Counter(tokenized_toy_example)\n",
    "tokens_and_frequencies.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This was all done with the toy_example, let's now do it with the 20_newsgroup data\n",
    "\n",
    "\n",
    "### Finding the (token, frequency) tuples over the entire 20 newsgroup data set\n",
    "# NOTE: you don't need to run this if you have the *20_newsgroup_tokens_and_frequencies.pickle* file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '\\\\\\\\?\\\\' + os.path.abspath(os.path.join(os.getcwd(), '20_newsgroups'))\n",
    "subdirectory_list = ['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
    "with open('20_newsgroup_content_dictionary.pickle', 'rb') as handle:\n",
    "    data_20_newsgroup = pickle.load(handle)\n",
    "\n",
    "'''\n",
    "recall that the data_20_newsgroup dictionary is formatted as: \n",
    "\n",
    "data_20_newsgroup = {\n",
    "\n",
    "    'alt.atheism' : {\n",
    "\n",
    "                        '49960' : [ list of all the valid lines in file 49960 in the 'alt.atheism' subdirectory ],\n",
    "\n",
    "                        '51060' : [ list of all the valid lines in file 51060 in the 'alt.atheism' subdirectory ],\n",
    "\n",
    "                        ...\n",
    "\n",
    "                    },\n",
    "\n",
    "    'comp.graphics' : {\n",
    "\n",
    "                          '37261': [ list of all the valid lines in file 37261 in the 'comp.graphics' subdirectory ],\n",
    "\n",
    "                          '37913': [ list of all the valid lines in file 37913 in the 'comp.graphics' subdirectory ],\n",
    "\n",
    "                          ...\n",
    "\n",
    "                      } ,\n",
    "\n",
    "    ...\n",
    "\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "data_20_newsgroup_tokens = []\n",
    "\n",
    "for topic_name, topic_dictionary in data_20_newsgroup.items():\n",
    "    for filename, content_lines_in_filename in topic_dictionary.items():\n",
    "        print(f\"iterating over {topic_name} , {filename}\")\n",
    "        \n",
    "        # content_lines_in_filename is a list of strings where each string is an untokenized line \n",
    "        # (i.e. the string representation of the line in the file).\n",
    "        \n",
    "        # tokenizing the list\n",
    "        tokenized_content_lines = tokenize(content_lines_in_filename) # returns a list\n",
    "\n",
    "        # adding the tokens to the \n",
    "        for token in tokenized_content_lines: \n",
    "            data_20_newsgroup_tokens.append(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_20_newsgroup_tokens_and_frequencies = Counter(data_20_newsgroup_tokens)\n",
    "with open('20_newsgroup_tokens_and_frequencies.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_20_newsgroup_tokens_and_frequencies, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20_newsgroup_tokens_and_frequencies.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_20_newsgroup_tokens_and_frequencies.items())[0:10])\n",
    "print(list(data.items())[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeating the (token, frequency) computing code but in a topic-specific manner\n",
    "\n",
    "# DON'T NEED TO DO THIS IF YOU HAVE THE *20_newsgroup_tokens_and_frequencies_by_topics_dictionary.pickle* FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20_newsgroup_content_dictionary.pickle', 'rb') as handle:\n",
    "    data_20_newsgroup = pickle.load(handle)\n",
    "assert data_20_newsgroup == super_dictionary\n",
    "'''\n",
    "recall that the data_20_newsgroup dictionary is formatted as: \n",
    "\n",
    "data_20_newsgroup = {\n",
    "\n",
    "    'alt.atheism' : {\n",
    "\n",
    "                        '49960' : [ list of all the valid lines in file 49960 in the 'alt.atheism' subdirectory ],\n",
    "\n",
    "                        '51060' : [ list of all the valid lines in file 51060 in the 'alt.atheism' subdirectory ],\n",
    "\n",
    "                        ...\n",
    "\n",
    "                    },\n",
    "\n",
    "    'comp.graphics' : {\n",
    "\n",
    "                          '37261': [ list of all the valid lines in file 37261 in the 'comp.graphics' subdirectory ],\n",
    "\n",
    "                          '37913': [ list of all the valid lines in file 37913 in the 'comp.graphics' subdirectory ],\n",
    "\n",
    "                          ...\n",
    "\n",
    "                      } ,\n",
    "\n",
    "    ...\n",
    "\n",
    "}\n",
    "\n",
    "'''\n",
    "\n",
    "data_20_newsgroup_tokens_by_topics = {\n",
    "    'alt.atheism' : [],\n",
    "    'comp.graphics' : [],\n",
    "    'comp.os.ms-windows.misc' : [],\n",
    "    'comp.sys.ibm.pc.hardware' : [],\n",
    "    'comp.sys.mac.hardware' : [],\n",
    "    'comp.windows.x' : [],\n",
    "    'misc.forsale' : [],\n",
    "    'rec.autos' : [],\n",
    "    'rec.motorcycles' : [],\n",
    "    'rec.sport.baseball' : [],\n",
    "    'rec.sport.hockey' : [],\n",
    "    'sci.crypt' : [],\n",
    "    'sci.electronics' : [],\n",
    "    'sci.med' : [],\n",
    "    'sci.space' : [],\n",
    "    'soc.religion.christian' : [],\n",
    "    'talk.politics.guns' : [],\n",
    "    'talk.politics.mideast' : [],\n",
    "    'talk.politics.misc' : [],\n",
    "    'talk.religion.misc' : []\n",
    "}\n",
    "\n",
    "for topic_name, topic_dictionary in data_20_newsgroup.items():\n",
    "    print(f\"iterating over {topic_name}\")\n",
    "\n",
    "    tokens_in_this_topics_files = []\n",
    "    \n",
    "    for filename, content_lines_in_filename in topic_dictionary.items():\n",
    "        \n",
    "        # tokenizing the list\n",
    "        tokenized_content_lines = tokenize(content_lines_in_filename) # returns a list\n",
    "\n",
    "        # adding the tokens to the tokens_in_this_topics_files list\n",
    "        for token in tokenized_content_lines: \n",
    "            tokens_in_this_topics_files.append(token)\n",
    "        \n",
    "    this_topics_tokens_and_frequencies = Counter(tokens_in_this_topics_files)\n",
    "    this_topic_tokens_and_frequencies_as_list_of_tuples = [ (tok,freq) for (tok,freq) in this_topics_tokens_and_frequencies.items() ]\n",
    "\n",
    "    data_20_newsgroup_tokens_by_topics[topic_name] = this_topic_tokens_and_frequencies_as_list_of_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('20_newsgroup_tokens_and_frequencies_by_topics_dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_20_newsgroup_tokens_by_topics, handle)\n",
    "with open('20_newsgroup_tokens_and_frequencies_by_topics_dictionary.pickle', 'rb') as handle:\n",
    "    x = pickle.load(handle)\n",
    "print((x == data_20_newsgroup_tokens_by_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Storage - Industry Sector\n",
    "### This notebook assumes that you've downloaded the [industry sector](https://people.cs.umass.edu/~mccallum/data.html) and unpacked the tarball in the same directory as this notebook. \n",
    "\n",
    "### You should therefore have a folder called \"sector\" in the same directory as this notebook. The \"sector\" folder should have 12 subfolders (\"energy.sector\", \"capital.goods.sector\", etc...), each containing a long list of subfolders, themselves containing html-like documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File Format - Industry Sector\n",
    "### Trying to find a good \"landmark line\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '\\\\\\\\?\\\\' + os.path.abspath(os.path.join(os.getcwd(), 'sector'))\n",
    "openable_file_count = 0\n",
    "file_count = 0\n",
    "landmark_count = 0\n",
    "strangely_encoded_files = []\n",
    "annoying_notebook_files_count = 0\n",
    "landmarkless_files = []\n",
    "\n",
    "for dirname, dirnames, filenames in os.walk(root_dir):\n",
    "    # print path to all subdirectories first.\n",
    "    for subdirname in dirnames:\n",
    "        #print(os.path.join(dirname, subdirname))\n",
    "        pass\n",
    "\n",
    "    # print path to all filenames.\n",
    "    annoying_notebook_files = [ x for x in filenames if '.onetoc2' in x ]\n",
    "    annoying_notebook_files_count += len(annoying_notebook_files)\n",
    "    for notebookfile in annoying_notebook_files:\n",
    "        filenames.remove(notebookfile)\n",
    "        \n",
    "    file_count += len(filenames)\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        with open(os.path.join(dirname, filename),'r', errors='ignore') as infile:\n",
    "            contents = infile.readlines()\n",
    "            found_landmark = False\n",
    "            for line in contents:\n",
    "                if 'content-type: text/html' in line.lower():\n",
    "                    landmark_count += 1\n",
    "                    found_landmark = True\n",
    "                    break\n",
    "            if not found_landmark: \n",
    "                landmarkless_files.append(dirname+filename)\n",
    "            openable_file_count += 1\n",
    "        \n",
    "\n",
    "print(f\"examined {openable_file_count}/{file_count} and counted {landmark_count} 'Content-type: text/html' lines\")\n",
    "print('found {} notebook files (ignoring them)'.format(str(annoying_notebook_files_count)))\n",
    "print('these {} files did not have the landmark:\\n\\n{}'.format( str(len(landmarkless_files)), '\\n\\n'.join(landmarkless_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It seems like the line \"Content-type: text/html\" is a good landmark line, so now I'm going to initialize and populate the sector_super_dictionary.\n",
    "# NOTE: this dictionary has one level more than the previous super_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_subtopic_map = {\n",
    "    \"100\" : \"sector\\\\basic.materials.sector\\\\chemical.manufacturing.industry\",\n",
    "    \"101\" : \"sector\\\\basic.materials.sector\\\\chemicals.plastics.and.rubber.industry\",\n",
    "    \"102\" : \"sector\\\\basic.materials.sector\\\\containers.and.packaging.industry\",\n",
    "    \"103\" : \"sector\\\\basic.materials.sector\\\\fabricated.plastic.and.rubber.industry\",\n",
    "    \"104\" : \"sector\\\\basic.materials.sector\\\\forestry.and.wood.products.industry\",\n",
    "    \"105\" : \"sector\\\\basic.materials.sector\\\\gold.and.silver.industry\",\n",
    "    \"106\" : \"sector\\\\basic.materials.sector\\\\iron.and.steel.industry\",\n",
    "    \"107\" : \"sector\\\\basic.materials.sector\\\\metal.and.mining.industry\",\n",
    "    \"108\" : \"sector\\\\basic.materials.sector\\\\misc.fabricated.products.industry\",\n",
    "    \"109\" : \"sector\\\\basic.materials.sector\\\\paper.and.paper.products.industry\",\n",
    "    \"110\" : \"sector\\\\capital.goods.sector\\\\aerospace.and.defense.industry\",\n",
    "    \"111\" : \"sector\\\\capital.goods.sector\\\\construction.sector\\\\construction-raw.materials.industry\",\n",
    "    \"112\" : \"sector\\\\capital.goods.sector\\\\construction.sector\\\\construction-supplies.and.fixtures.industry\",\n",
    "    \"113\" : \"sector\\\\capital.goods.sector\\\\construction.sector\\\\construction.and.agricultural.machinery.industry\",\n",
    "    \"114\" : \"sector\\\\capital.goods.sector\\\\construction.sector\\\\construction.services.industry\",\n",
    "    \"115\" : \"sector\\\\capital.goods.sector\\\\misc.capital.goods.industry\",\n",
    "    \"116\" : \"sector\\\\capital.goods.sector\\\\mobile.homes.and.rvs.industry\",\n",
    "    \"117\" : \"sector\\\\conglomerates.industry\",\n",
    "    \"118\" : \"sector\\\\consumer.cyclical.sector\\\\appliance.and.tool.industry\",\n",
    "    \"119\" : \"sector\\\\consumer.cyclical.sector\\\\audio.and.video.equipment.industry\",\n",
    "    \"120\" : \"sector\\\\consumer.cyclical.sector\\\\auto.sector\\\\auto.and.truck.manufacturers.industry\",\n",
    "    \"121\" : \"sector\\\\consumer.cyclical.sector\\\\auto.sector\\\\auto.and.truck.parts.industry\",\n",
    "    \"122\" : \"sector\\\\consumer.cyclical.sector\\\\footwear.industry\",\n",
    "    \"123\" : \"sector\\\\consumer.cyclical.sector\\\\furniture.and.fixtures.industry\",\n",
    "    \"124\" : \"sector\\\\consumer.cyclical.sector\\\\jewelry.and.silverware.industry\",\n",
    "    \"125\" : \"sector\\\\consumer.cyclical.sector\\\\photography.industry\",\n",
    "    \"126\" : \"sector\\\\consumer.cyclical.sector\\\\recreational.products.industry\",\n",
    "    \"127\" : \"sector\\\\consumer.cyclical.sector\\\\textiles.non.apparel.industry\",\n",
    "    \"128\" : \"sector\\\\consumer.cyclical.sector\\\\tires.industry\",\n",
    "    \"129\" : \"sector\\\\consumer.non-cyclical.sector\\\\beverages.sector\\\\alcoholic.beverages.industry\",\n",
    "    \"130\" : \"sector\\\\consumer.non-cyclical.sector\\\\beverages.sector\\\\non.alcoholic.beverages.industry\",\n",
    "    \"131\" : \"sector\\\\consumer.non-cyclical.sector\\\\crops.industry\",\n",
    "    \"132\" : \"sector\\\\consumer.non-cyclical.sector\\\\fish.livestock.industry\",\n",
    "    \"133\" : \"sector\\\\consumer.non-cyclical.sector\\\\food.processing.industry\",\n",
    "    \"134\" : \"sector\\\\consumer.non-cyclical.sector\\\\office.supplies.industry\",\n",
    "    \"135\" : \"sector\\\\consumer.non-cyclical.sector\\\\personal.and.household.products.industry\",\n",
    "    \"136\" : \"sector\\\\consumer.non-cyclical.sector\\\\tobacco.industry\",\n",
    "    \"137\" : \"sector\\\\energy.sector\\\\coal.industry\",\n",
    "    \"138\" : \"sector\\\\energy.sector\\\\oil.and.gas.integrated.industry\",\n",
    "    \"139\" : \"sector\\\\energy.sector\\\\oil.and.gas.operations.industry\",\n",
    "    \"140\" : \"sector\\\\energy.sector\\\\oil.well.services.and.equipment.industry\",\n",
    "    \"141\" : \"sector\\\\financial.sector\\\\banking.sector\\\\money.center.banks.industry\",\n",
    "    \"142\" : \"sector\\\\financial.sector\\\\banking.sector\\\\regional.banks.industry\",\n",
    "    \"143\" : \"sector\\\\financial.sector\\\\banking.sector\\\\s.and.ls.savings.banks.industry\",\n",
    "    \"144\" : \"sector\\\\financial.sector\\\\consumer.financial.services.industry\",\n",
    "    \"145\" : \"sector\\\\financial.sector\\\\insurance.sector\\\\accident.and.health.insurance.industry\",\n",
    "    \"146\" : \"sector\\\\financial.sector\\\\insurance.sector\\\\life.insurance.industry\",\n",
    "    \"147\" : \"sector\\\\financial.sector\\\\insurance.sector\\\\misc.insurance.industry\",\n",
    "    \"148\" : \"sector\\\\financial.sector\\\\insurance.sector\\\\property.and.casualty.insurance.industry\",\n",
    "    \"149\" : \"sector\\\\financial.sector\\\\investment.services.industry\",\n",
    "    \"150\" : \"sector\\\\financial.sector\\\\misc.financial.services.industry\",\n",
    "    \"151\" : \"sector\\\\healthcare.sector\\\\biotechnology.and.drugs.industry\",\n",
    "    \"152\" : \"sector\\\\healthcare.sector\\\\healthcare.facilities.industry\",\n",
    "    \"153\" : \"sector\\\\healthcare.sector\\\\major.drugs.industry\",\n",
    "    \"154\" : \"sector\\\\healthcare.sector\\\\medical.equipment.and.supplies.industry\",\n",
    "    \"155\" : \"sector\\\\services.sector\\\\advertising.industry\",\n",
    "    \"156\" : \"sector\\\\services.sector\\\\broadcasting.and.cable.tv.industry\",\n",
    "    \"157\" : \"sector\\\\services.sector\\\\business.services.industry\",\n",
    "    \"158\" : \"sector\\\\services.sector\\\\casinos.and.gambling.industry\",\n",
    "    \"159\" : \"sector\\\\services.sector\\\\communications.services.industry\",\n",
    "    \"160\" : \"sector\\\\services.sector\\\\hotels.and.motels.industry\",\n",
    "    \"161\" : \"sector\\\\services.sector\\\\law.sector\\\\immigration.law.industry\",\n",
    "    \"162\" : \"sector\\\\services.sector\\\\law.sector\\\\international.law.industry\",\n",
    "    \"163\" : \"sector\\\\services.sector\\\\law.sector\\\\maritime.law.industry\",\n",
    "    \"164\" : \"sector\\\\services.sector\\\\law.sector\\\\trade.law.industry\",\n",
    "    \"165\" : \"sector\\\\services.sector\\\\motion.pictures.industry\",\n",
    "    \"166\" : \"sector\\\\services.sector\\\\personal.services.industry\",\n",
    "    \"167\" : \"sector\\\\services.sector\\\\printing.and.publishing.industry\",\n",
    "    \"168\" : \"sector\\\\services.sector\\\\printing.services.industry\",\n",
    "    \"169\" : \"sector\\\\services.sector\\\\real.estate.operations.industry\",\n",
    "    \"170\" : \"sector\\\\services.sector\\\\recreational.activities.industry\",\n",
    "    \"171\" : \"sector\\\\services.sector\\\\rental.and.leasing.industry\",\n",
    "    \"172\" : \"sector\\\\services.sector\\\\restaurants.industry\",\n",
    "    \"173\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.apparel.industry\",\n",
    "    \"174\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.catalog.and.mail.order.industry\",\n",
    "    \"175\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.department.and.discount.industry\",\n",
    "    \"176\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.drugs.industry\",\n",
    "    \"177\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.grocery.industry\",\n",
    "    \"178\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.home.improvement.industry\",\n",
    "    \"179\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.specialty.industry\",\n",
    "    \"180\" : \"sector\\\\services.sector\\\\retail.sector\\\\retail.technology.industry\",\n",
    "    \"181\" : \"sector\\\\services.sector\\\\schools.industry\",\n",
    "    \"182\" : \"sector\\\\services.sector\\\\security.systems.and.services.industry\",\n",
    "    \"183\" : \"sector\\\\services.sector\\\\waste.management.services.industry\",\n",
    "    \"184\" : \"sector\\\\technology.sector\\\\communications.equipment.industry\",\n",
    "    \"185\" : \"sector\\\\technology.sector\\\\computer.sector\\\\computer.hardware.industry\",\n",
    "    \"186\" : \"sector\\\\technology.sector\\\\computer.sector\\\\computer.networks.industry\",\n",
    "    \"187\" : \"sector\\\\technology.sector\\\\computer.sector\\\\computer.peripherals.industry\",\n",
    "    \"188\" : \"sector\\\\technology.sector\\\\computer.sector\\\\computer.services.industry\",\n",
    "    \"189\" : \"sector\\\\technology.sector\\\\computer.sector\\\\computer.storage.devices.industry\",\n",
    "    \"190\" : \"sector\\\\technology.sector\\\\computer.sector\\\\software.and.programming.industry\",\n",
    "    \"191\" : \"sector\\\\technology.sector\\\\electronic.instruments.and.controls.industry\",\n",
    "    \"192\" : \"sector\\\\technology.sector\\\\office.equipment.industry\",\n",
    "    \"193\" : \"sector\\\\technology.sector\\\\scientific.and.technical.instruments.industry\",\n",
    "    \"194\" : \"sector\\\\technology.sector\\\\semiconductors.industry\",\n",
    "    \"195\" : \"sector\\\\transportation.sector\\\\air.courier.industry\",\n",
    "    \"196\" : \"sector\\\\transportation.sector\\\\airline.industry\",\n",
    "    \"197\" : \"sector\\\\transportation.sector\\\\misc.transportation.industry\",\n",
    "    \"198\" : \"sector\\\\transportation.sector\\\\railroad.industry\",\n",
    "    \"199\" : \"sector\\\\transportation.sector\\\\trucking.industry\",\n",
    "    \"200\" : \"sector\\\\transportation.sector\\\\water.transportation.industry\",\n",
    "    \"201\" : \"sector\\\\utilities.sector\\\\electric.utilities.industry\",\n",
    "    \"202\" : \"sector\\\\utilities.sector\\\\natural.gas.industry\",\n",
    "    \"203\" : \"sector\\\\utilities.sector\\\\water.utilities.industry\"\n",
    "}\n",
    "\n",
    "data_industry_sector_tokens_by_topics = {}\n",
    "for key in key_subtopic_map.keys():\n",
    "    data_industry_sector_tokens_by_topics[key] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populating sector_super_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '\\\\\\\\?\\\\' + os.path.abspath(os.path.join(os.getcwd()))\n",
    "file_count = 0\n",
    "all_tokens_in_data_set = []\n",
    "\n",
    "for key, subtopic_path in key_subtopic_map.items():\n",
    "    tokens_in_this_subtopics_files = []\n",
    "    for file in os.listdir(os.path.abspath(os.path.join(root_dir, subtopic_path ))):\n",
    "        lines_with_valid_content = []\n",
    "        with open(os.path.abspath(os.path.join(root_dir, subtopic_path, file )), 'r', errors='ignore') as inputfile:\n",
    "            contents = inputfile.readlines()\n",
    "        for i, line in enumerate(contents):\n",
    "            if \"content-type: text/html\" in line.lower():\n",
    "                lines_with_valid_content.append(line.rstrip())\n",
    "                break\n",
    "        i += 1\n",
    "        while i < len(contents):\n",
    "            lines_with_valid_content.append(contents[i].rstrip())\n",
    "            i += 1\n",
    "        tokenized_content_lines = tokenize(lines_with_valid_content) # returns a list\n",
    "\n",
    "        # adding the tokens to the tokens_in_this_topics_files list\n",
    "        for token in tokenized_content_lines: \n",
    "            tokens_in_this_subtopics_files.append(token)\n",
    "            all_tokens_in_data_set.append(token)\n",
    "        \n",
    "    this_subtopics_tokens_and_frequencies = Counter(tokens_in_this_subtopics_files)\n",
    "    this_subtopic_tokens_and_frequencies_as_list_of_tuples = [ (tok,freq) for (tok,freq) in this_subtopics_tokens_and_frequencies.items() ]\n",
    "\n",
    "    data_industry_sector_tokens_by_topics[key] = this_subtopic_tokens_and_frequencies_as_list_of_tuples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Content-type', 77),\n",
       " ('text/html', 132),\n",
       " ('Generated', 6),\n",
       " ('by', 85),\n",
       " ('the', 764),\n",
       " ('Home', 55),\n",
       " ('Page', 41),\n",
       " ('Wizard', 6),\n",
       " ('CompuServe', 6),\n",
       " ('Inc.', 152),\n",
       " ('Last', 8),\n",
       " ('Updated', 6),\n",
       " ('Jul', 6),\n",
       " ('html', 54),\n",
       " ('The', 128),\n",
       " ('following', 31),\n",
       " ('HTML', 124),\n",
       " ('tags', 21),\n",
       " ('are', 117),\n",
       " ('header', 10),\n",
       " ('and', 1039),\n",
       " ('title', 70),\n",
       " ('These', 17),\n",
       " ('allows', 10),\n",
       " ('you', 89),\n",
       " ('to', 554),\n",
       " ('specify', 7),\n",
       " ('a', 898),\n",
       " ('for', 308),\n",
       " ('this', 68),\n",
       " ('page', 16),\n",
       " ('head', 57),\n",
       " ('NuCO2', 1),\n",
       " ('/title', 55),\n",
       " ('/head', 54),\n",
       " ('BODY', 51),\n",
       " ('BACKGROUND=', 15),\n",
       " ('Bubbles.gif', 5),\n",
       " ('CENTER', 144),\n",
       " ('TABLE', 38),\n",
       " ('BORDER', 5),\n",
       " ('TR', 388),\n",
       " ('TD', 807),\n",
       " ('STRONG', 43),\n",
       " ('FONT', 156),\n",
       " ('SIZE=3', 3),\n",
       " ('Best', 2),\n",
       " ('viewed', 2),\n",
       " ('with', 161),\n",
       " ('Netscape', 4),\n",
       " ('href=', 824),\n",
       " ('http', 239),\n",
       " ('//home.netscape.com/comprod/upgrades/index.html', 1),\n",
       " ('IMG', 219),\n",
       " ('SRC=', 130),\n",
       " ('aninet30.gif', 1),\n",
       " ('/STRONG', 42),\n",
       " ('/FONT', 161),\n",
       " ('SIZE', 16),\n",
       " ('/a', 717),\n",
       " ('/TD', 807),\n",
       " ('/TR', 394),\n",
       " ('/TABLE', 38),\n",
       " ('/CENTER', 67),\n",
       " ('p', 595),\n",
       " ('/p', 503),\n",
       " ('COLOR=', 16),\n",
       " ('BIG', 1),\n",
       " ('FONT=', 1),\n",
       " ('Baskerville', 1),\n",
       " ('SIZE=7', 1),\n",
       " ('BOLD', 13),\n",
       " ('NuCo', 6),\n",
       " ('SUB', 9),\n",
       " ('/SUB', 9),\n",
       " ('USA', 8),\n",
       " ('Co', 4),\n",
       " ('nnection', 1),\n",
       " ('/BOLD', 10),\n",
       " ('/BIG', 1),\n",
       " ('/P', 123),\n",
       " ('ADDRESS', 1),\n",
       " ('H2', 31),\n",
       " ('ALIGN=', 191),\n",
       " ('center', 363),\n",
       " ('NASDAQ-NNM', 1),\n",
       " ('NUCO', 1),\n",
       " ('/center', 103),\n",
       " ('/H2', 30),\n",
       " ('SE', 1),\n",
       " ('Market', 4),\n",
       " ('Place', 2),\n",
       " ('Stuart', 1),\n",
       " ('Florida', 3),\n",
       " ('B', 245),\n",
       " ('Phone', 126),\n",
       " ('/B', 239),\n",
       " ('Fax', 42),\n",
       " ('A', 787),\n",
       " ('HREF=', 611),\n",
       " ('Picnuc2.gif', 2),\n",
       " ('Micservice.gif', 1),\n",
       " ('Height=35', 9),\n",
       " ('Width=141', 9),\n",
       " ('depot.GIF', 3),\n",
       " ('Micservmap.gif', 1),\n",
       " ('Trade.html', 2),\n",
       " ('Micassoc2.gif', 1),\n",
       " ('Bulk.html', 2),\n",
       " ('micsystem.gif', 1),\n",
       " ('//quote.yahoo.com/quotes', 4),\n",
       " ('SYMBOLS=NUCO', 2),\n",
       " ('detailed=t', 4),\n",
       " ('Micnews.gif', 1),\n",
       " ('Employ.html', 2),\n",
       " ('Micemploy.gif', 1),\n",
       " ('Benefit.html', 2),\n",
       " ('Micbene.gif', 1),\n",
       " ('//www.micell.com/', 2),\n",
       " ('micmcell.gif', 1),\n",
       " ('//www.geotech.co.uk', 2),\n",
       " ('enviro.gif', 1),\n",
       " ('H4', 9),\n",
       " ('Service', 12),\n",
       " ('Current', 9),\n",
       " ('Areas', 2),\n",
       " ('Associations', 1),\n",
       " ('Systems', 26),\n",
       " ('/A', 609),\n",
       " ('/H4', 7),\n",
       " ('News', 25),\n",
       " ('Releases', 8),\n",
       " ('Employment', 29),\n",
       " ('Benefits', 3),\n",
       " ('of', 631),\n",
       " ('Bulk', 8),\n",
       " ('CO2', 20),\n",
       " ('MiCELL', 1),\n",
       " ('Environmental', 13),\n",
       " ('Instruments', 1),\n",
       " ('br', 608),\n",
       " ('line54.gif', 3),\n",
       " ('height=10', 4),\n",
       " ('width=700', 3),\n",
       " ('is', 176),\n",
       " ('just', 7),\n",
       " ('plain', 6),\n",
       " ('text', 30),\n",
       " ('U', 49),\n",
       " ('Company', 74),\n",
       " ('/U', 48),\n",
       " ('has', 58),\n",
       " ('established', 8),\n",
       " ('itself', 2),\n",
       " ('as', 104),\n",
       " ('leader', 16),\n",
       " ('in', 397),\n",
       " ('bulk', 12),\n",
       " ('CO', 3),\n",
       " ('industry', 36),\n",
       " ('supplying', 1),\n",
       " ('liquid', 6),\n",
       " ('carbon', 4),\n",
       " ('dioxide', 4),\n",
       " ('systems', 48),\n",
       " ('fountain', 6),\n",
       " ('beverage', 4),\n",
       " ('operations', 24),\n",
       " ('serves', 7),\n",
       " ('diverse', 6),\n",
       " ('customer', 22),\n",
       " ('base', 8),\n",
       " ('ranging', 1),\n",
       " ('from', 55),\n",
       " ('airports', 1),\n",
       " ('Z', 1),\n",
       " ('zoo', 1),\n",
       " (\"'s\", 151),\n",
       " ('Just', 3),\n",
       " ('about', 24),\n",
       " ('any', 16),\n",
       " ('place', 5),\n",
       " ('serving', 5),\n",
       " ('beverages', 3),\n",
       " ('Already', 1),\n",
       " ('largest', 17),\n",
       " ('company', 71),\n",
       " ('presently', 2),\n",
       " ('operates', 7),\n",
       " ('states', 1),\n",
       " ('objective', 2),\n",
       " ('expand', 2),\n",
       " ('its', 43),\n",
       " ('business', 43),\n",
       " ('nationally', 1),\n",
       " ('establish', 3),\n",
       " ('preferred', 10),\n",
       " ('supplier', 20),\n",
       " ('Nucobroc.gif', 1),\n",
       " ('height=400', 1),\n",
       " ('width=450', 1),\n",
       " ('Thsystem.gif', 1),\n",
       " ('height=120', 1),\n",
       " ('width=95', 1),\n",
       " ('Left', 12),\n",
       " ('time.gif', 1),\n",
       " ('height=55', 1),\n",
       " ('width=55', 1),\n",
       " ('clock', 2),\n",
       " ('ticking', 1),\n",
       " ('Do', 2),\n",
       " (\"n't\", 2),\n",
       " ('lose', 1),\n",
       " ('money', 1),\n",
       " ('Take', 10),\n",
       " ('advantage', 3),\n",
       " ('our', 168),\n",
       " ('system', 23),\n",
       " ('reap', 1),\n",
       " ('rewards', 1),\n",
       " ('drinks', 1),\n",
       " ('high', 42),\n",
       " ('profit', 4),\n",
       " ('margins.', 1),\n",
       " ('mailto', 57),\n",
       " ('Nuco2', 1),\n",
       " ('earthlink.net', 1),\n",
       " ('ama022.gif', 1),\n",
       " ('height=60', 1),\n",
       " ('width=75', 2),\n",
       " ('Font', 1),\n",
       " ('Size=2', 1),\n",
       " ('Questions', 5),\n",
       " ('Comments', 3),\n",
       " ('nuco2.earthlink.net', 1),\n",
       " ('Click', 12),\n",
       " ('Here', 1),\n",
       " ('//home.earthlink.net/cgi-bin/counter.pl', 1),\n",
       " ('H3', 19),\n",
       " ('Visitors', 3),\n",
       " ('have', 54),\n",
       " ('stopped', 1),\n",
       " ('since', 9),\n",
       " ('/H3', 19),\n",
       " ('FONT=Times', 1),\n",
       " ('New', 84),\n",
       " ('Roman', 28),\n",
       " ('SIZE=4', 4),\n",
       " ('I', 55),\n",
       " ('registered', 5),\n",
       " ('trademark.', 1),\n",
       " ('COLOR', 6),\n",
       " ('/I', 41),\n",
       " ('body', 64),\n",
       " ('FONT=NEW', 4),\n",
       " ('COURIER', 4),\n",
       " ('SIZE=6', 3),\n",
       " ('BLINK', 2),\n",
       " ('/BLINK', 2),\n",
       " ('greenball.gif', 6),\n",
       " ('bottom', 21),\n",
       " ('reducesf.html', 1),\n",
       " ('Enhances', 1),\n",
       " ('Guest', 1),\n",
       " ('Satisfaction', 1),\n",
       " ('safer.html', 1),\n",
       " ('Safety', 3),\n",
       " ('requires.html', 1),\n",
       " ('Requires', 2),\n",
       " ('Less', 2),\n",
       " ('Service/Eliminates', 1),\n",
       " ('Downtime', 1),\n",
       " ('reduces.html', 1),\n",
       " ('Reduces', 2),\n",
       " ('Operating', 7),\n",
       " ('Costs', 1),\n",
       " ('security.html', 1),\n",
       " ('Security', 12),\n",
       " ('space.html', 1),\n",
       " ('Saves', 1),\n",
       " ('Space', 2),\n",
       " ('/body', 52),\n",
       " ('/html', 53),\n",
       " ('Center', 11),\n",
       " ('Which', 1),\n",
       " ('would', 8),\n",
       " ('choose', 1),\n",
       " ('SIZE=1', 2),\n",
       " ('Low', 3),\n",
       " ('Pressure', 3),\n",
       " ('System', 21),\n",
       " ('Bulk3.gif', 1),\n",
       " ('height=200', 2),\n",
       " ('width=160', 2),\n",
       " ('High2.gif', 1),\n",
       " ('High', 6),\n",
       " ('Cylinders', 2),\n",
       " ('titlt', 1),\n",
       " ('allow', 5),\n",
       " ('on', 121),\n",
       " ('NuCo2', 4),\n",
       " ('employment', 4),\n",
       " ('opportunities', 13),\n",
       " ('SIZE=5', 2),\n",
       " ('Sales', 63),\n",
       " ('FONT=TIMES', 1),\n",
       " ('NEW', 24),\n",
       " ('ROMAN', 1),\n",
       " ('If', 23),\n",
       " ('an', 77),\n",
       " ('energetic', 2),\n",
       " ('individual', 7),\n",
       " ('experience', 32),\n",
       " ('field', 7),\n",
       " ('sales', 64),\n",
       " ('knowledgeable', 1),\n",
       " ('food', 1),\n",
       " ('may', 19),\n",
       " ('be', 80),\n",
       " ('opportunity', 3),\n",
       " ('All', 13),\n",
       " ('serious', 1),\n",
       " ('inquiries', 1),\n",
       " ('call', 3),\n",
       " ('tag', 10),\n",
       " ('This', 35),\n",
       " ('defines', 5),\n",
       " ('portion', 6),\n",
       " ('or', 132),\n",
       " ('document', 13),\n",
       " ('reduce', 9),\n",
       " ('operating', 8),\n",
       " ('costs', 8),\n",
       " ('eliminating', 1),\n",
       " ('need', 11),\n",
       " ('provide', 24),\n",
       " ('manpower', 2),\n",
       " ('manage', 4),\n",
       " ('keep', 3),\n",
       " ('track', 2),\n",
       " ('cylinders', 11),\n",
       " ('available', 15),\n",
       " ('receive', 3),\n",
       " ('deliveries', 1),\n",
       " ('install', 1),\n",
       " ('new', 37),\n",
       " ('gas', 6),\n",
       " ('consumed', 1),\n",
       " ('Gas', 4),\n",
       " ('usage', 1),\n",
       " ('reduced', 6),\n",
       " ('unlike', 2),\n",
       " ('where', 10),\n",
       " ('invariably', 1),\n",
       " ('lost', 2),\n",
       " ('when', 6),\n",
       " ('less-than-empty', 1),\n",
       " ('changed', 1),\n",
       " ('based', 9),\n",
       " ('perceived', 1),\n",
       " ('weight', 1),\n",
       " ('vessels', 2),\n",
       " ('serve', 14),\n",
       " ('constant', 1),\n",
       " ('reservoirs', 2),\n",
       " ('which', 27),\n",
       " ('refilled', 2),\n",
       " ('according', 2),\n",
       " ('contents', 1),\n",
       " ('gauge', 1),\n",
       " ('estimated', 1),\n",
       " ('that', 85),\n",
       " ('users', 3),\n",
       " ('will', 84),\n",
       " ('generally', 3),\n",
       " ('savings', 5),\n",
       " ('less', 5),\n",
       " ('product', 48),\n",
       " ('waste.', 1),\n",
       " ('plumbed', 1),\n",
       " ('outside', 5),\n",
       " ('24-hour', 1),\n",
       " ('seven', 3),\n",
       " ('day', 1),\n",
       " ('week', 1),\n",
       " ('service', 28),\n",
       " ('Therefore', 10),\n",
       " ('can', 22),\n",
       " ('specialized', 5),\n",
       " ('delivery', 9),\n",
       " ('truck', 1),\n",
       " ('without', 5),\n",
       " ('assistance', 4),\n",
       " ('personnel', 6),\n",
       " ('during', 6),\n",
       " ('peak', 1),\n",
       " ('non-business', 1),\n",
       " ('hours', 2),\n",
       " ('eliminates', 3),\n",
       " ('remove', 1),\n",
       " ('transport', 1),\n",
       " ('pressure', 9),\n",
       " ('avoids', 1),\n",
       " ('wear', 4),\n",
       " ('hazards', 1),\n",
       " ('associated', 3),\n",
       " ('such', 10),\n",
       " ('handling', 4),\n",
       " ('With', 8),\n",
       " ('user', 2),\n",
       " ('experiences', 1),\n",
       " ('downtime', 2),\n",
       " ('replaced', 1),\n",
       " ('often', 2),\n",
       " ('occurs', 1),\n",
       " ('prior', 6),\n",
       " ('warning', 1),\n",
       " ('result', 6),\n",
       " ('carbonated', 2),\n",
       " ('no', 12),\n",
       " ('refilling', 1),\n",
       " ('refill', 1),\n",
       " ('process', 18),\n",
       " ('does', 6),\n",
       " ('not', 21),\n",
       " ('interrupt', 1),\n",
       " ('flow', 5),\n",
       " ('drink', 1),\n",
       " ('machines', 3),\n",
       " ('continuous', 4),\n",
       " ('critical', 3),\n",
       " ('customers', 57),\n",
       " ('represent', 2),\n",
       " ('highly', 7),\n",
       " ('profitable', 3),\n",
       " ('item', 2),\n",
       " ('Safer', 1),\n",
       " ('store', 2),\n",
       " ('at', 73),\n",
       " ('lbs', 1),\n",
       " ('per', 18),\n",
       " ('square', 1),\n",
       " ('inch', 1),\n",
       " ('quot', 45),\n",
       " ('psi', 2),\n",
       " ('versus', 1),\n",
       " ('required', 7),\n",
       " ('Since', 7),\n",
       " ('risk', 1),\n",
       " ('explosion', 1),\n",
       " ('inherent', 1),\n",
       " ('substantially', 3),\n",
       " ('eliminated', 3),\n",
       " ('conversion', 3),\n",
       " ('results', 9),\n",
       " ('lower', 4),\n",
       " ('insurance', 5),\n",
       " ('worker', 1),\n",
       " ('compensation', 4),\n",
       " ('rates', 2),\n",
       " ('In', 25),\n",
       " ('addition', 8),\n",
       " ('employee', 6),\n",
       " ('heavy', 3),\n",
       " ('steel', 3),\n",
       " ('installation', 4),\n",
       " ('stationary', 1),\n",
       " ('systems.', 1),\n",
       " ('Customer', 5),\n",
       " ('security', 11),\n",
       " ('enhanced', 4),\n",
       " ('because', 2),\n",
       " ('require', 2),\n",
       " ('inside', 4),\n",
       " ('access', 6),\n",
       " ('facility', 10),\n",
       " ('utilizes', 2),\n",
       " ('locking', 1),\n",
       " ('device', 4),\n",
       " ('fill', 4),\n",
       " ('port', 2),\n",
       " ('eliminate', 3),\n",
       " ('possibility', 1),\n",
       " ('tampering', 1),\n",
       " ('only', 6),\n",
       " ('it', 30),\n",
       " ('vitrually', 1),\n",
       " ('elimiinates', 1),\n",
       " ('pilfrage.', 1),\n",
       " ('One', 2),\n",
       " ('lb', 12),\n",
       " ('vessel', 1),\n",
       " ('size', 8),\n",
       " ('gallon', 2),\n",
       " ('household', 2),\n",
       " ('water', 32),\n",
       " ('heater', 1),\n",
       " ('stores', 2),\n",
       " ('much', 4),\n",
       " ('twenty', 1),\n",
       " ('takes', 4),\n",
       " ('up', 24),\n",
       " ('space', 2),\n",
       " ('within', 9),\n",
       " ('environment', 4),\n",
       " ('premium.', 1),\n",
       " ('Trade', 2),\n",
       " ('members', 9),\n",
       " ('trade', 17),\n",
       " ('associations', 1),\n",
       " ('LEFT', 81),\n",
       " ('//www1.fns.net/flrestaurant/', 1),\n",
       " ('Fra.gif', 1),\n",
       " ('Height=150', 1),\n",
       " ('width=150', 1),\n",
       " ('SIZE=2', 5),\n",
       " ('Restaurant', 2),\n",
       " ('Association', 9),\n",
       " ('FRA', 2),\n",
       " ('recognized', 4),\n",
       " ('one', 16),\n",
       " ('leading', 23),\n",
       " ('organizations', 3),\n",
       " ('state', 4),\n",
       " ('was', 25),\n",
       " ('founded', 2),\n",
       " ('over', 20),\n",
       " ('years', 28),\n",
       " ('provided', 5),\n",
       " ('improving', 1),\n",
       " ('enhancing', 4),\n",
       " ('operational', 1),\n",
       " ('efficiencies', 4),\n",
       " ('creative', 2),\n",
       " ('programming', 2),\n",
       " ('pursuing', 1),\n",
       " ('fair/equitable', 1),\n",
       " ('foodservice', 3),\n",
       " ('legislation.', 1),\n",
       " ('/bold', 2),\n",
       " ('//www.restaurant.org/', 1),\n",
       " ('nra.gif', 1),\n",
       " ('height=100', 3),\n",
       " ('width=300', 1),\n",
       " ('For', 30),\n",
       " ('more', 50),\n",
       " ('than', 31),\n",
       " ('National', 6),\n",
       " ('NRA', 2),\n",
       " ('been', 16),\n",
       " ('resource', 2),\n",
       " ('community', 7),\n",
       " ('provides', 14),\n",
       " ('educational', 2),\n",
       " ('research', 11),\n",
       " ('communications', 10),\n",
       " ('convention', 1),\n",
       " ('programs', 17),\n",
       " ('government', 2),\n",
       " ('affairs', 1),\n",
       " ('wide', 15),\n",
       " ('array', 2),\n",
       " ('other', 46),\n",
       " ('services', 38),\n",
       " ('It', 16),\n",
       " ('mission', 7),\n",
       " ('protect', 1),\n",
       " ('educate', 1),\n",
       " ('promote', 2),\n",
       " ('//www.nwsa.com', 1),\n",
       " ('nwsa.gif', 1),\n",
       " ('width=140', 9),\n",
       " ('Welding', 5),\n",
       " ('Supply', 7),\n",
       " ('NWSA', 1),\n",
       " ('welding', 1),\n",
       " ('supply', 8),\n",
       " ('industrial', 44),\n",
       " ('distributors', 2),\n",
       " ('programs/services', 1),\n",
       " ('help', 16),\n",
       " ('achieve', 7),\n",
       " ('their', 15),\n",
       " ('common', 3),\n",
       " ('goals', 4),\n",
       " ('safety', 15),\n",
       " ('awareness', 3),\n",
       " ('improved', 9),\n",
       " ('profitability.', 1),\n",
       " ('Aoa.gif', 1),\n",
       " ('Width=140', 1),\n",
       " ('AOA', 1),\n",
       " ('incorporated', 1),\n",
       " ('merger', 1),\n",
       " ('two', 19),\n",
       " ('well', 9),\n",
       " ('jobber', 1),\n",
       " ('Alabama', 2),\n",
       " ('Petroleum', 1),\n",
       " ('Marketers', 1),\n",
       " ('Independent', 1),\n",
       " ('Oilmen', 1),\n",
       " ('AOA/AACS', 1),\n",
       " ('non-profit', 1),\n",
       " ('association', 2),\n",
       " ('appoximately', 1),\n",
       " ('wholesale', 2),\n",
       " ('petroleum', 1),\n",
       " ('marketers', 2),\n",
       " ('convenience', 2),\n",
       " ('across', 1),\n",
       " ('Alabama.', 1),\n",
       " ('/Bold', 1),\n",
       " ('/Font', 1),\n",
       " ('Size', 2),\n",
       " ('//www.cstorecentral.com/public/nacs/05.htm', 1),\n",
       " ('nacs.gif', 1),\n",
       " ('height=45', 1),\n",
       " ('Convenience', 1),\n",
       " ('Stores', 1),\n",
       " ('NACS', 1),\n",
       " ('international', 29),\n",
       " ('represents', 3),\n",
       " ('retail', 4),\n",
       " ('companies', 5),\n",
       " ('United', 17),\n",
       " ('States', 15),\n",
       " ('all', 39),\n",
       " ('world', 27),\n",
       " ('main', 14),\n",
       " ('focus', 5),\n",
       " ('date', 1),\n",
       " ('issues.', 1),\n",
       " ('/font', 587),\n",
       " ('Last-modified', 20),\n",
       " ('Thu', 2),\n",
       " ('Nov', 4),\n",
       " ('GMT', 29),\n",
       " ('Content-length', 19),\n",
       " ('DOCTYPE', 46),\n",
       " ('PUBLIC', 46),\n",
       " ('-//SQ//DTD', 10),\n",
       " ('extensions//EN', 10),\n",
       " ('hmpro3.dtd', 10),\n",
       " ('HEAD', 47),\n",
       " ('TITLE', 46),\n",
       " ('ADMTronics', 10),\n",
       " ('/TITLE', 46),\n",
       " ('/HEAD', 45),\n",
       " ('BGCOLOR=', 24),\n",
       " ('DEDEDE', 6),\n",
       " ('graphics/admlogo.gif', 10),\n",
       " ('BORDER=', 42),\n",
       " ('P', 676),\n",
       " ('SIZE=', 78),\n",
       " ('0000A0', 10),\n",
       " ('technology', 50),\n",
       " ('developer', 1),\n",
       " ('manufacturer', 14),\n",
       " ('BR', 713),\n",
       " ('Cutting', 1),\n",
       " ('Edge', 2),\n",
       " ('Medical', 3),\n",
       " ('Electronic', 36),\n",
       " ('Devices', 1),\n",
       " ('WIDTH=', 91),\n",
       " ('//www.sonotron.com/', 1),\n",
       " ('graphics/buttons/sonodev.gif', 1),\n",
       " ('vet-sono.htm', 1),\n",
       " ('graphics/buttons/vetsono.gif', 1),\n",
       " ('graphics/buttons/nccd.gif', 1),\n",
       " ('graphics/buttons/Aurex-3.gif', 1),\n",
       " ('Environmentally', 1),\n",
       " ('Friendly', 1),\n",
       " ('Water', 1),\n",
       " ('Based', 1),\n",
       " ('Chemicals', 137),\n",
       " ('primers.htm', 1),\n",
       " ('graphics/buttons/primers.gif', 1),\n",
       " ('additivs.htm', 1),\n",
       " ('graphics/buttons/additive.gif', 1),\n",
       " ('rescoats.htm', 1),\n",
       " ('graphics/buttons/rescoat.gif', 1),\n",
       " ('labladhe.htm', 1),\n",
       " ('graphics/buttons/labladhe.gif', 1),\n",
       " ('Professional', 6),\n",
       " ('Products', 99),\n",
       " ('dermatol.htm', 1),\n",
       " ('graphics/buttons/dermatol.gif', 1),\n",
       " ('makeup.htm', 1),\n",
       " ('graphics/buttons/makeup.gif', 1),\n",
       " ('General', 23),\n",
       " ('Information', 44),\n",
       " ('mgtnpers.htm', 1),\n",
       " ('graphics/buttons/mgtpers.gif', 1),\n",
       " ('directns.htm', 1),\n",
       " ('graphics/buttons/Directns.gif', 1),\n",
       " ('like', 14),\n",
       " ('current', 13),\n",
       " ('financial', 5),\n",
       " ('information', 65),\n",
       " ('ADM', 30),\n",
       " ('Tronics', 29),\n",
       " ('//www.nasdaq.com/', 1),\n",
       " ('graphics/nasdaq.gif', 1),\n",
       " ('click', 3),\n",
       " ('here', 12),\n",
       " ('type', 4),\n",
       " ('ADMT.', 1),\n",
       " ('admtronics.com', 8),\n",
       " ('graphics/emailwht.gif', 6),\n",
       " ('MIDDLE', 8),\n",
       " ('HEIGHT=', 41),\n",
       " ('copy', 24),\n",
       " ('0000FF', 22),\n",
       " ('FF0000', 11),\n",
       " ('WEBVERTISEMENT', 1),\n",
       " ('SUP', 2),\n",
       " ('SM', 1),\n",
       " ('/SUP', 2),\n",
       " ('Designed', 1),\n",
       " ('Hosted', 1),\n",
       " ('//www.ccinyc.com/', 1),\n",
       " ('//www.ccinyc.com/graphics/logos/cnlogos.gif', 1),\n",
       " ('/BODY', 45),\n",
       " ('/HTML', 46),\n",
       " ('Fri', 12),\n",
       " ('Oct', 9),\n",
       " ('Additives', 2),\n",
       " ('955.htm', 1),\n",
       " ('Defoamer', 1),\n",
       " ('850.htm', 1),\n",
       " ('Phystat', 1),\n",
       " ('452.htm', 1),\n",
       " ('Staticon', 1),\n",
       " ('HR', 90),\n",
       " ('224-S', 6),\n",
       " ('Pegasus', 9),\n",
       " ('Avenue', 17),\n",
       " ('Northvale', 6),\n",
       " ('Jersey', 29),\n",
       " ('Tel', 10),\n",
       " ('links.htm', 9),\n",
       " ('Links', 9),\n",
       " ('Dematology/Prosthetics', 1),\n",
       " ('DFDFDF', 2),\n",
       " ('Dermatology/Prosthetics', 1),\n",
       " ('nobumps.htm', 1),\n",
       " ('graphics/buttons/nobumps.gif', 1),\n",
       " ('prosaide.htm', 2),\n",
       " ('graphics/buttons/prosaid1.gif', 2),\n",
       " ('Directions', 1),\n",
       " ('DIRECTIONS', 1),\n",
       " ('TO', 61),\n",
       " ('TRONICS', 1),\n",
       " ('BY', 9),\n",
       " ('CAR', 1),\n",
       " ('BLOCKQUOTE', 9),\n",
       " ('From', 8),\n",
       " ('York', 7),\n",
       " ('City', 11),\n",
       " ('George', 5),\n",
       " ('Washington', 4),\n",
       " ('Bridge', 7),\n",
       " ('Palisades', 4),\n",
       " ('Parkway', 4),\n",
       " ('North', 24),\n",
       " ('Exit', 2),\n",
       " ('5S', 2),\n",
       " ('Route', 7),\n",
       " ('South', 20),\n",
       " ('Proceed', 3),\n",
       " ('third', 5),\n",
       " ('traffic', 2),\n",
       " ('light', 5),\n",
       " ('McDonald', 3),\n",
       " ('corner', 3),\n",
       " ('make', 16),\n",
       " ('left', 125),\n",
       " ('onto', 7),\n",
       " ('right.', 1),\n",
       " ('Turnpike', 3),\n",
       " ('towards', 1),\n",
       " ('before', 7),\n",
       " ('enter', 3),\n",
       " ('follow', 6),\n",
       " ('directions', 4),\n",
       " ('above.', 4),\n",
       " ('Western', 6),\n",
       " ('Pennsylvania', 3),\n",
       " ('East', 18),\n",
       " ('NJ', 40),\n",
       " ('State', 11),\n",
       " ('England', 15),\n",
       " ('Tappan', 2),\n",
       " ('Zee', 2),\n",
       " ('signs', 9),\n",
       " ('exit', 5),\n",
       " ('/BLOCKQUOTE', 9),\n",
       " ('TRUCK', 1),\n",
       " ('9W', 2),\n",
       " ('Go', 5),\n",
       " ('miles', 3),\n",
       " ('Closter', 2),\n",
       " ('Dock', 5),\n",
       " ('Road', 46),\n",
       " ('Make', 4),\n",
       " ('go', 1),\n",
       " ('lights', 1),\n",
       " ('including', 38),\n",
       " ('Blinkers', 1),\n",
       " ('right', 290),\n",
       " ('Piermont', 1),\n",
       " ('Paris', 1),\n",
       " ('first', 15),\n",
       " ('Livingston', 1),\n",
       " ('loading', 2),\n",
       " ('dock', 2),\n",
       " ('rear.', 2),\n",
       " ('Labeling', 6),\n",
       " ('Adhesives', 2),\n",
       " ('stiktotn.htm', 1),\n",
       " ('Stiktotin', 1),\n",
       " ('Label', 1),\n",
       " ('Pastes', 1),\n",
       " ('Makeup', 2),\n",
       " ('amp', 66),\n",
       " ('Special', 4),\n",
       " ('Effects', 2),\n",
       " ('prosaid2.htm', 1),\n",
       " ('graphics/buttons/prosaid2.gif', 1),\n",
       " ('prepaide.htm', 1),\n",
       " ('graphics/buttons/prepaide.gif', 1),\n",
       " ('postaide.htm', 1),\n",
       " ('graphics/buttons/postaide.gif', 1),\n",
       " ('aquacrem.htm', 1),\n",
       " ('graphics/buttons/aquacrem.gif', 1),\n",
       " ('Management', 10),\n",
       " ('Personnel', 2),\n",
       " ('DBDBDB', 2),\n",
       " ('graphics/alfonso.gif', 1),\n",
       " ('VALIGN=', 1),\n",
       " ('Dr', 9),\n",
       " ('A.', 9),\n",
       " ('DiMino', 3),\n",
       " ('President', 32),\n",
       " ('Founder', 1),\n",
       " ('Andre', 1),\n",
       " ('Executive', 10),\n",
       " ('Vice', 16),\n",
       " ('COO', 1),\n",
       " ('E-mail', 18),\n",
       " ('andre', 2),\n",
       " ('Vincent', 1),\n",
       " ('Production', 11),\n",
       " ('Gordon', 1),\n",
       " ('Beguhn', 1),\n",
       " ('Gordon.B', 2),\n",
       " ('MCI1.com', 2),\n",
       " ('Jack', 1),\n",
       " ('Dill', 1),\n",
       " ('Manager', 51),\n",
       " ('Tim', 1),\n",
       " ('Gilmartin', 1),\n",
       " ('Plant', 19),\n",
       " ('Michael', 2),\n",
       " ('Clark', 3),\n",
       " ('International', 57),\n",
       " ('Marketing', 5),\n",
       " ('Representative', 16),\n",
       " ('sonotron', 2),\n",
       " ('juno.com', 2),\n",
       " ('Jenny', 2),\n",
       " ('Di', 1),\n",
       " ('Mino', 1),\n",
       " ('Alice', 1),\n",
       " ('Riva', 1),\n",
       " ('Henry', 2),\n",
       " ('Weidemann', 1),\n",
       " ('Primers', 3),\n",
       " ('108-w.htm', 1),\n",
       " ('Aquaforte', 1),\n",
       " ('108-W', 1),\n",
       " ('73f.htm', 1),\n",
       " ('Polaqua', 6),\n",
       " ('73F', 1),\n",
       " ('103.htm', 1),\n",
       " ('103-l.htm', 1),\n",
       " ('103-L', 1),\n",
       " ('127-07.htm', 1),\n",
       " ('138.htm', 1),\n",
       " ('w7.htm', 1),\n",
       " ('W7', 1),\n",
       " ('Resins', 2),\n",
       " ('Coatings', 23),\n",
       " ('180-7.htm', 1),\n",
       " ('Santel', 8),\n",
       " ('4362.htm', 1),\n",
       " ('hr-79.htm', 1),\n",
       " ('HR-97', 1),\n",
       " ('hr-98.htm', 1),\n",
       " ('HR-98', 1),\n",
       " ('hr98-ttl.htm', 1),\n",
       " ('HR98-TTL', 1),\n",
       " ('toridex.htm', 1),\n",
       " ('Toridex', 1),\n",
       " ('WR-17', 1),\n",
       " ('Vet-Sonotron', 2),\n",
       " ('VET-SONOTRON', 1),\n",
       " ('EQUI-TECH', 1),\n",
       " ('THERAPY', 1),\n",
       " ('see', 14),\n",
       " ('count', 5),\n",
       " ('finish', 1),\n",
       " ('line', 25),\n",
       " ('Therapeutic', 1),\n",
       " ('Technology', 19),\n",
       " ('Horses', 2),\n",
       " ('Equi-Tech', 8),\n",
       " ('Therapy', 8),\n",
       " ('uses', 3),\n",
       " ('most', 10),\n",
       " ('advanced', 12),\n",
       " ('treating', 1),\n",
       " ('joint', 7),\n",
       " ('problems', 5),\n",
       " ('horses', 5),\n",
       " ('proven', 6),\n",
       " ('lameness', 4),\n",
       " ('increase', 12),\n",
       " ('range', 21),\n",
       " ('motion', 3),\n",
       " ('controlled', 6),\n",
       " ('laboratory', 9),\n",
       " ('studies', 3),\n",
       " ('therapy', 1),\n",
       " ('harmful', 2),\n",
       " ('side', 2),\n",
       " ('effects', 4),\n",
       " ('non-invasive', 1),\n",
       " ('cause', 1),\n",
       " ('pain', 2),\n",
       " ('safe', 3),\n",
       " ('efficient', 2),\n",
       " ('way', 6),\n",
       " ('improve', 15),\n",
       " ('condition', 2),\n",
       " ('problems.', 1),\n",
       " ('Laboratory', 4),\n",
       " ('Tested', 1),\n",
       " ('Extensive', 1),\n",
       " ('double-blind', 1),\n",
       " ('were', 12),\n",
       " ('conducted', 4),\n",
       " ('ponies', 1),\n",
       " ('induced', 1),\n",
       " ('arthritis', 1),\n",
       " ('University', 7),\n",
       " ('Wisconsin', 7),\n",
       " ('Veterinary', 3),\n",
       " ('School', 2),\n",
       " ('showed', 1),\n",
       " ('used', 16),\n",
       " ('level', 5),\n",
       " ('increased', 5),\n",
       " ('Swelling', 1),\n",
       " ('gait', 1),\n",
       " ('analysis', 14),\n",
       " ('revealed', 1),\n",
       " ('marked', 1),\n",
       " ('improvement', 8),\n",
       " ('study', 2),\n",
       " ('published', 3),\n",
       " ('respected', 1),\n",
       " ('Canadian', 1),\n",
       " ('Journal', 2),\n",
       " ('Research', 13),\n",
       " ('early', 7),\n",
       " ('Results', 2),\n",
       " ('Track', 1),\n",
       " ('treated', 2),\n",
       " ('perform', 2),\n",
       " ('better', 14),\n",
       " ('As', 6),\n",
       " ('example', 4),\n",
       " ('Wajastar', 3),\n",
       " ('year', 11),\n",
       " ('old', 1),\n",
       " ('diagnosed', 1),\n",
       " ('having', 2),\n",
       " ('degenerative', 1),\n",
       " ('disease', 3),\n",
       " ('syndrome', 1),\n",
       " ('osteoarthritis', 1),\n",
       " ('rear', 1),\n",
       " ('hock', 1),\n",
       " ('some', 13),\n",
       " ('secondary', 1),\n",
       " ('sensitivity', 1),\n",
       " ('back', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_industry_sector_tokens_by_topics[\"100\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239860\n"
     ]
    }
   ],
   "source": [
    "all_tokens_and_token_frequencies_in_data_set = Counter(all_tokens_in_data_set)\n",
    "all_tokens_and_token_frequencies_in_data_set_as_list_of_tuples = [ (tok,freq) for (tok,freq) in all_tokens_and_token_frequencies_in_data_set.items() ]\n",
    "print(len(all_tokens_and_token_frequencies_in_data_set_as_list_of_tuples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "8653\n",
      "6813\n",
      "False\n",
      "6761\n",
      "False\n",
      "5922\n",
      "False\n",
      "6270\n",
      "False\n",
      "7578\n",
      "False\n",
      "8224\n",
      "False\n",
      "6474\n",
      "False\n",
      "9927\n",
      "False\n",
      "6812\n",
      "False\n",
      "6247\n",
      "False\n",
      "2984\n",
      "False\n",
      "6957\n",
      "False\n",
      "7416\n",
      "False\n",
      "6290\n",
      "False\n",
      "6407\n",
      "False\n",
      "5162\n",
      "False\n",
      "8163\n",
      "False\n",
      "7880\n",
      "False\n",
      "9061\n",
      "False\n",
      "6968\n",
      "False\n",
      "6533\n",
      "False\n",
      "6472\n",
      "False\n",
      "7239\n",
      "False\n",
      "7718\n",
      "False\n",
      "7218\n",
      "False\n",
      "7698\n",
      "False\n",
      "7530\n",
      "False\n",
      "2969\n",
      "False\n",
      "6410\n",
      "False\n",
      "3248\n",
      "False\n",
      "3236\n",
      "False\n",
      "4435\n",
      "False\n",
      "8574\n",
      "False\n",
      "6369\n",
      "False\n",
      "6344\n",
      "False\n",
      "4092\n",
      "False\n",
      "5732\n",
      "False\n",
      "8637\n",
      "False\n",
      "6659\n",
      "False\n",
      "7325\n",
      "False\n",
      "8884\n",
      "False\n",
      "6786\n",
      "False\n",
      "6706\n",
      "False\n",
      "7474\n",
      "False\n",
      "5895\n",
      "False\n",
      "7276\n",
      "False\n",
      "6682\n",
      "False\n",
      "8367\n",
      "False\n",
      "9518\n",
      "False\n",
      "7282\n",
      "False\n",
      "7642\n",
      "False\n",
      "9636\n",
      "False\n",
      "6979\n",
      "False\n",
      "6876\n",
      "False\n",
      "5320\n",
      "False\n",
      "8120\n",
      "False\n",
      "7091\n",
      "False\n",
      "9195\n",
      "False\n",
      "11086\n",
      "False\n",
      "7808\n",
      "False\n",
      "11876\n",
      "False\n",
      "10774\n",
      "False\n",
      "13593\n",
      "False\n",
      "7826\n",
      "False\n",
      "9189\n",
      "False\n",
      "4965\n",
      "False\n",
      "9141\n",
      "False\n",
      "6646\n",
      "False\n",
      "8372\n",
      "False\n",
      "11158\n",
      "False\n",
      "7993\n",
      "False\n",
      "7318\n",
      "False\n",
      "7591\n",
      "False\n",
      "6298\n",
      "False\n",
      "6797\n",
      "False\n",
      "8021\n",
      "False\n",
      "7383\n",
      "False\n",
      "6188\n",
      "False\n",
      "7646\n",
      "False\n",
      "8696\n",
      "False\n",
      "8082\n",
      "False\n",
      "8863\n",
      "False\n",
      "9294\n",
      "False\n",
      "8083\n",
      "False\n",
      "9503\n",
      "False\n",
      "7776\n",
      "False\n",
      "7176\n",
      "False\n",
      "7588\n",
      "False\n",
      "7670\n",
      "False\n",
      "9161\n",
      "False\n",
      "6854\n",
      "False\n",
      "8192\n",
      "False\n",
      "8946\n",
      "False\n",
      "8184\n",
      "False\n",
      "6738\n",
      "False\n",
      "8753\n",
      "False\n",
      "7512\n",
      "False\n",
      "7414\n",
      "False\n",
      "7103\n",
      "False\n",
      "3862\n",
      "False\n",
      "9723\n",
      "False\n",
      "7466\n",
      "False\n",
      "6084\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(len(data_industry_sector_tokens_by_topics))\n",
    "for i,x in enumerate(data_industry_sector_tokens_by_topics.keys()):\n",
    "    \n",
    "    print(len(data_industry_sector_tokens_by_topics[x]))\n",
    "    if i > 0:\n",
    "        print(data_industry_sector_tokens_by_topics[x] == data_industry_sector_tokens_by_topics[list(data_industry_sector_tokens_by_topics.keys())[i-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_industry_sector_tokens_by_topics, key_subtopic_map\n",
    "with open('industry_sector_tokens_and_frequencies_by_topics_dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(data_industry_sector_tokens_by_topics, handle)\n",
    "with open('industry_sector_key_subtopic_mapping_dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(key_subtopic_map, handle)\n",
    "with open('industry_sector_tokens_and_frequencies_across_dataset_list_of_tuples.pickle','wb') as handle:\n",
    "    pickle.dump(all_tokens_and_token_frequencies_in_data_set_as_list_of_tuples, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
